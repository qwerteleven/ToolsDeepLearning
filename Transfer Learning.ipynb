{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofZLXdw9XAXT"
   },
   "source": [
    "# <center> Pretrained Models - TranferLearning </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNi5_IsfYUqe"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os \n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import tensorflow        as tf\n",
    "import sklearn           as sk\n",
    "\n",
    "from tensorflow.keras.models                import Sequential, Model\n",
    "from tensorflow.keras.layers                import Dense, Input, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.layers                import BatchNormalization, Dropout, Reshape, Activation, ReLU\n",
    "from tensorflow.keras.layers                import Conv2DTranspose, UpSampling2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image   import ImageDataGenerator\n",
    "from tensorflow.keras.utils                 import to_categorical\n",
    "from tensorflow.keras.optimizers            import SGD\n",
    "\n",
    "from skimage.transform       import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadImagesDirectory(directory):\n",
    "    files =[x[0] for x in os.walk(directory)]  # uses carefully, is long dataset\n",
    "    data = []\n",
    "    labels = []\n",
    "    label = -1\n",
    "    print(files[1:])\n",
    "    for f1 in files[1:]:\n",
    "        label += 1\n",
    "        \n",
    "        data_path = os.path.join(f1, '*g') \n",
    "        files_ = glob.glob(data_path) \n",
    "        \n",
    "        for image in files_:\n",
    "            img = cv2.imread(image)\n",
    "            if img is None:\n",
    "                continue\n",
    "            res = cv2.resize(img, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
    "            data.append(res)\n",
    "            \n",
    "        labels += ([label] * (len(data) - len(labels)))\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./PetImages/train\\\\cat', './PetImages/train\\\\dog']\n",
      "['./PetImages/test\\\\cat', './PetImages/test\\\\dog']\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = loadImagesDirectory(\"./PetImages/train\")\n",
    "\n",
    "x_test, y_test = loadImagesDirectory(\"./PetImages/test\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332827,
     "status": "ok",
     "timestamp": 1559072322102,
     "user": {
      "displayName": "qwerteleven kuihuih",
      "photoUrl": "",
      "userId": "17420874050594162777"
     },
     "user_tz": -60
    },
    "id": "QJ2grYK6cpfH",
    "outputId": "fcd64992-a937-406f-e717-8ca000dcc370"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "Y_train = tf.keras.utils.to_categorical(y_train)\n",
    "Y_test  = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "test_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332827,
     "status": "ok",
     "timestamp": 1559072322102,
     "user": {
      "displayName": "qwerteleven kuihuih",
      "photoUrl": "",
      "userId": "17420874050594162777"
     },
     "user_tz": -60
    },
    "id": "QJ2grYK6cpfH",
    "outputId": "fcd64992-a937-406f-e717-8ca000dcc370"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(2,2), strides=1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(2,2), strides=1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(2,2), strides=1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332827,
     "status": "ok",
     "timestamp": 1559072322102,
     "user": {
      "displayName": "qwerteleven kuihuih",
      "photoUrl": "",
      "userId": "17420874050594162777"
     },
     "user_tz": -60
    },
    "id": "QJ2grYK6cpfH",
    "outputId": "fcd64992-a937-406f-e717-8ca000dcc370"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=SGD(0.05), loss='binary_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332827,
     "status": "ok",
     "timestamp": 1559072322102,
     "user": {
      "displayName": "qwerteleven kuihuih",
      "photoUrl": "",
      "userId": "17420874050594162777"
     },
     "user_tz": -60
    },
    "id": "QJ2grYK6cpfH",
    "outputId": "fcd64992-a937-406f-e717-8ca000dcc370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "554/553 [==============================] - 77s 139ms/step - loss: 0.3006 - accuracy: 0.8692 - val_loss: 0.3737 - val_accuracy: 0.8349\n",
      "Epoch 2/20\n",
      "554/553 [==============================] - 77s 138ms/step - loss: 0.2989 - accuracy: 0.8706 - val_loss: 0.3852 - val_accuracy: 0.8394\n",
      "Epoch 3/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2857 - accuracy: 0.8785 - val_loss: 0.3797 - val_accuracy: 0.8429\n",
      "Epoch 4/20\n",
      "554/553 [==============================] - 77s 138ms/step - loss: 0.2836 - accuracy: 0.8785 - val_loss: 0.3847 - val_accuracy: 0.8314\n",
      "Epoch 5/20\n",
      "554/553 [==============================] - 79s 142ms/step - loss: 0.2792 - accuracy: 0.8821 - val_loss: 0.3645 - val_accuracy: 0.8416\n",
      "Epoch 6/20\n",
      "554/553 [==============================] - 78s 140ms/step - loss: 0.2702 - accuracy: 0.8828 - val_loss: 0.3989 - val_accuracy: 0.8299\n",
      "Epoch 7/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2658 - accuracy: 0.8885 - val_loss: 0.3774 - val_accuracy: 0.8447\n",
      "Epoch 8/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2632 - accuracy: 0.8879 - val_loss: 0.4307 - val_accuracy: 0.8227\n",
      "Epoch 9/20\n",
      "554/553 [==============================] - 77s 139ms/step - loss: 0.2592 - accuracy: 0.8914 - val_loss: 0.3694 - val_accuracy: 0.8430\n",
      "Epoch 10/20\n",
      "554/553 [==============================] - 77s 138ms/step - loss: 0.2513 - accuracy: 0.8946 - val_loss: 0.4478 - val_accuracy: 0.8169\n",
      "Epoch 11/20\n",
      "554/553 [==============================] - 76s 137ms/step - loss: 0.2451 - accuracy: 0.8966 - val_loss: 0.5054 - val_accuracy: 0.8147\n",
      "Epoch 12/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2414 - accuracy: 0.8970 - val_loss: 0.5048 - val_accuracy: 0.8237\n",
      "Epoch 13/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2383 - accuracy: 0.8985 - val_loss: 0.4869 - val_accuracy: 0.8085\n",
      "Epoch 14/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2315 - accuracy: 0.9036 - val_loss: 0.4275 - val_accuracy: 0.8477\n",
      "Epoch 15/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2285 - accuracy: 0.9040 - val_loss: 0.3833 - val_accuracy: 0.8495\n",
      "Epoch 16/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2232 - accuracy: 0.9081 - val_loss: 0.5578 - val_accuracy: 0.7859\n",
      "Epoch 17/20\n",
      "554/553 [==============================] - 77s 138ms/step - loss: 0.2194 - accuracy: 0.9073 - val_loss: 0.3977 - val_accuracy: 0.8462\n",
      "Epoch 18/20\n",
      "554/553 [==============================] - 77s 138ms/step - loss: 0.2124 - accuracy: 0.9090 - val_loss: 0.3970 - val_accuracy: 0.8476\n",
      "Epoch 19/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2073 - accuracy: 0.9137 - val_loss: 0.4648 - val_accuracy: 0.8256\n",
      "Epoch 20/20\n",
      "554/553 [==============================] - 76s 138ms/step - loss: 0.2026 - accuracy: 0.9190 - val_loss: 0.3959 - val_accuracy: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1baf60ba488>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir=\"logs/Convolutional-dog-cat-profiler\"\n",
    "\n",
    "\n",
    "# tf.profiler.experimental.start(logdir=logdir)\n",
    "\n",
    "metricsCallback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/Convolutional-dog-cat-metrics\")\n",
    "\n",
    "model.fit(train_datagen.flow(x_train, Y_train, batch_size=32),\n",
    "          steps_per_epoch=len(x_train) / 32,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=[metricsCallback],\n",
    "          validation_data=test_datagen.flow(x_test, Y_test, batch_size=32))\n",
    "\n",
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models-save/DogCat-Convolutional-86-83\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./models-save/DogCat-Convolutional-86-83\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tranfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "68608000/68606236 [==============================] - 33s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7741,
     "status": "ok",
     "timestamp": 1559073348402,
     "user": {
      "displayName": "qwerteleven kuihuih",
      "photoUrl": "",
      "userId": "17420874050594162777"
     },
     "user_tz": -60
    },
    "id": "MdC6DLjQ-U9z",
    "outputId": "1b648452-815a-4038-ec7f-09f3c4275d44"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\"./cats_and_dogs_filtered/train\",\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=32,\n",
    "                                             image_size=(160, 160))\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\"./cats_and_dogs_filtered/validation\",\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=32,\n",
    "                                                  image_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5, 5, 512)\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = model(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation batches: 26\n",
      "Number of test batches: 6\n"
     ]
    }
   ],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use buffered prefetching to load images from disk without having I/O become blocking\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 6s 102ms/step - loss: 2.8953 - accuracy: 0.5810 - val_loss: 1.8851 - val_accuracy: 0.6485\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 2.4036 - accuracy: 0.6230 - val_loss: 1.4234 - val_accuracy: 0.7116\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 2.0133 - accuracy: 0.6525 - val_loss: 1.1480 - val_accuracy: 0.7525\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 1.8778 - accuracy: 0.6855 - val_loss: 0.9021 - val_accuracy: 0.7958\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 1.7258 - accuracy: 0.6860 - val_loss: 0.8663 - val_accuracy: 0.8106\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 1.4621 - accuracy: 0.7305 - val_loss: 0.7500 - val_accuracy: 0.8391\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 1.4943 - accuracy: 0.7240 - val_loss: 0.6728 - val_accuracy: 0.8441\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 1.2568 - accuracy: 0.7540 - val_loss: 0.5397 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 1.2091 - accuracy: 0.7710 - val_loss: 0.4909 - val_accuracy: 0.8800\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 1.1575 - accuracy: 0.7765 - val_loss: 0.4510 - val_accuracy: 0.8824\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 1.0720 - accuracy: 0.7805 - val_loss: 0.4124 - val_accuracy: 0.8985\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.9831 - accuracy: 0.7955 - val_loss: 0.4124 - val_accuracy: 0.9035\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.8803 - accuracy: 0.8200 - val_loss: 0.3953 - val_accuracy: 0.9084\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.8850 - accuracy: 0.8095 - val_loss: 0.3716 - val_accuracy: 0.9109\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.8135 - accuracy: 0.8155 - val_loss: 0.3584 - val_accuracy: 0.9183\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.8318 - accuracy: 0.8205 - val_loss: 0.3697 - val_accuracy: 0.9158\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.7556 - accuracy: 0.8275 - val_loss: 0.3214 - val_accuracy: 0.9295\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7398 - accuracy: 0.8355 - val_loss: 0.3143 - val_accuracy: 0.9282\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6692 - accuracy: 0.8385 - val_loss: 0.2962 - val_accuracy: 0.9295\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6360 - accuracy: 0.8480 - val_loss: 0.3266 - val_accuracy: 0.9245\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  8\n"
     ]
    }
   ],
   "source": [
    "model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!tensorboard --logdir \"D:\\La cosa de Trabajo\\WorkSpaces\\Jupyter\\Notebook  Colab\\logs\\MINIS-convolutional-metrics\"\n",
    "--port 909\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 568,
     "status": "error",
     "timestamp": 1559073536570,
     "user": {
      "displayName": "qwerteleven kuihuih",
      "photoUrl": "",
      "userId": "17420874050594162777"
     },
     "user_tz": -60
    },
    "id": "ogI76p14-ddj",
    "outputId": "dde2ebf0-a284-4b83-84af-bb1db9785c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 0.6919 - accuracy: 0.8460 - val_loss: 0.3095 - val_accuracy: 0.9307\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.6708 - accuracy: 0.8495 - val_loss: 0.3331 - val_accuracy: 0.9257\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 6s 98ms/step - loss: 0.6693 - accuracy: 0.8400 - val_loss: 0.3176 - val_accuracy: 0.9282\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 6s 91ms/step - loss: 0.7338 - accuracy: 0.8450 - val_loss: 0.3142 - val_accuracy: 0.9270\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6117 - accuracy: 0.8510 - val_loss: 0.3307 - val_accuracy: 0.9220\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.6590 - accuracy: 0.8580 - val_loss: 0.2992 - val_accuracy: 0.9270\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6757 - accuracy: 0.8510 - val_loss: 0.2982 - val_accuracy: 0.9282\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6416 - accuracy: 0.8525 - val_loss: 0.3628 - val_accuracy: 0.9196\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6996 - accuracy: 0.8365 - val_loss: 0.3051 - val_accuracy: 0.9307\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6307 - accuracy: 0.8475 - val_loss: 0.3358 - val_accuracy: 0.9245\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6955 - accuracy: 0.8405 - val_loss: 0.3326 - val_accuracy: 0.9257\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 0.6293 - accuracy: 0.8595 - val_loss: 0.3312 - val_accuracy: 0.9245\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.6167 - accuracy: 0.8540 - val_loss: 0.3052 - val_accuracy: 0.9282\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.6930 - accuracy: 0.8450 - val_loss: 0.3283 - val_accuracy: 0.9245\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 6s 93ms/step - loss: 0.7046 - accuracy: 0.8415 - val_loss: 0.3314 - val_accuracy: 0.9270\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 6s 91ms/step - loss: 0.6735 - accuracy: 0.8465 - val_loss: 0.3160 - val_accuracy: 0.9270\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 6s 91ms/step - loss: 0.6169 - accuracy: 0.8535 - val_loss: 0.3168 - val_accuracy: 0.9257\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.6600 - accuracy: 0.8465 - val_loss: 0.3080 - val_accuracy: 0.9270\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.7267 - accuracy: 0.8495 - val_loss: 0.3058 - val_accuracy: 0.9282\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 6s 98ms/step - loss: 0.7030 - accuracy: 0.8520 - val_loss: 0.3394 - val_accuracy: 0.9233\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  10 + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         validation_data=validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de Notebook 13 - Modelos Preentrenados -.ipynb",
   "provenance": [
    {
     "file_id": "1IWFLc-JfvuL2KYpRU9o7397R_fasTy6D",
     "timestamp": 1559063556499
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
